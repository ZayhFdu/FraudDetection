{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data ADDRESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hostsNames = './data/WEBSPAM-UK2007-hostnames.txt'\n",
    "hostLables = './data/WEBSPAM-UK2007-SET1-labels.txt'\n",
    "graph = './data/uk-2007-05.hostgraph_weighted.graph-txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114529\n"
     ]
    }
   ],
   "source": [
    "with open(hostsNames, 'r') as f_Names:\n",
    "    ID2Name = {}\n",
    "    for line in f_Names:\n",
    "        line = line.strip().split()\n",
    "        hostID, hostName = line\n",
    "        ID2Name[hostID] = hostName\n",
    "\n",
    "print(len(ID2Name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4275\n"
     ]
    }
   ],
   "source": [
    "with open(hostLables, 'r') as f_Labels:\n",
    "    ID2Label = {}\n",
    "    for line in f_Labels:\n",
    "        line = line.strip().split()[:2]\n",
    "        hostID, hostLable = line\n",
    "        ID2Label[hostID] = hostLable\n",
    "\n",
    "print(len(ID2Label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1836441 (1861, '1631', '99948')\n"
     ]
    }
   ],
   "source": [
    "with open(graph, 'r') as f_graph:\n",
    "    edgeWeight = []\n",
    "    for nodei, line in enumerate(f_graph):\n",
    "        line = line.strip()\n",
    "        if nodei == 0 or not line:\n",
    "            continue\n",
    "        else:     \n",
    "            line = re.findall('[0-9]+:[0-9]+', line)\n",
    "            for pair in line:\n",
    "                nodej, weight = pair.split(':')\n",
    "                # print(nodei-1, nodej, weight)\n",
    "                edgeWeight.append((nodei - 1, nodej, weight))\n",
    "\n",
    "print(len(edgeWeight),max(edgeWeight, key=lambda x: x[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled data proportion: 0.03732679059452191, unlabeled data #: 110254\n"
     ]
    }
   ],
   "source": [
    "print(\"Labeled data proportion: {0}, unlabeled data #: {1}\".format(len(ID2Label)/len(ID2Name), len(ID2Name)-len(ID2Label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# SPAM: 222, # NONSPAM: 4053, PROPORTION: 0.05477424130273871\n"
     ]
    }
   ],
   "source": [
    "SPAM, NONSPAM = {}, {}\n",
    "for key, value in ID2Label.items():\n",
    "    if value == 'spam':\n",
    "        SPAM[key] = 1\n",
    "    else:\n",
    "        NONSPAM[key] = 0\n",
    "\n",
    "print(\"# SPAM: {0}, # NONSPAM: {1}, PROPORTION: {2}\".format(len(SPAM), len(NONSPAM), len(SPAM)/len(NONSPAM)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph = nx.Graph()\n",
    "\n",
    "for edge in edgeWeight:\n",
    "    nodei, nodej, weight = edge\n",
    "    Graph.add_edge(nodei, int(nodej), weight=float(weight))  # it's fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe9a699abe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nx.draw_networkx(Graph, pos=nx.circular_layout(Graph), with_labels=True) # Need far more research on drawing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import dgl.function as fn\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl import DGLGraph\n",
    "\n",
    "gcn_msg = fn.copy_src(src='h', out='m')\n",
    "gcn_reduce = fn.sum(msg='m', out='h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeApplyModule(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, activation):\n",
    "        super(NodeApplyModule, self).__init__()\n",
    "        self.linear = nn.Linear(in_feats, out_feats)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, node):\n",
    "        h = self.linear(node.data['h'])\n",
    "        h = self.activation(h)\n",
    "        return {'h' : h}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats, activation):\n",
    "        super(GCN, self).__init__()\n",
    "        self.apply_mod = NodeApplyModule(in_feats, out_feats, activation)\n",
    "\n",
    "    def forward(self, g, feature):\n",
    "        g.ndata['h'] = feature\n",
    "        g.update_all(gcn_msg, gcn_reduce)\n",
    "        g.apply_nodes(func=self.apply_mod)\n",
    "        return g.ndata.pop('h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (gcn1): GCN(\n",
      "    (apply_mod): NodeApplyModule(\n",
      "      (linear): Linear(in_features=1433, out_features=16, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (gcn2): GCN(\n",
      "    (apply_mod): NodeApplyModule(\n",
      "      (linear): Linear(in_features=16, out_features=7, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.gcn1 = GCN(1433, 16, F.relu)\n",
    "        self.gcn2 = GCN(16, 7, F.relu)\n",
    "\n",
    "    def forward(self, g, features):\n",
    "        x = self.gcn1(g, features)\n",
    "        x = self.gcn2(g, x)\n",
    "        return x\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.data import citation_graph as citegrh\n",
    "def load_cora_data():\n",
    "    data = citegrh.load_cora()\n",
    "    features = th.FloatTensor(data.features)\n",
    "    labels = th.LongTensor(data.labels)\n",
    "    train_mask = th.ByteTensor(data.train_mask)\n",
    "    val_mask = th.ByteTensor(data.val_mask)\n",
    "    test_mask = th.ByteTensor(data.test_mask)\n",
    "    g = data.graph\n",
    "    # add self loop\n",
    "    g.remove_edges_from(g.selfloop_edges())\n",
    "    g = DGLGraph(g)\n",
    "    g.add_edges(g.nodes(), g.nodes())\n",
    "    return g, features, labels, train_mask, val_mask, test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(logits, labels, mask):\n",
    "    with torch.no_grad():\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000 | Loss 0.6149 | Time(s) nan | Accuracy 0.6567\n",
      "Epoch 00001 | Loss 0.6127 | Time(s) nan | Accuracy 0.6600\n",
      "Epoch 00002 | Loss 0.6097 | Time(s) nan | Accuracy 0.6600\n",
      "Epoch 00003 | Loss 0.6071 | Time(s) 0.4085 | Accuracy 0.6567\n",
      "Epoch 00004 | Loss 0.6046 | Time(s) 0.4235 | Accuracy 0.6567\n",
      "Epoch 00005 | Loss 0.6021 | Time(s) 0.4155 | Accuracy 0.6567\n",
      "Epoch 00006 | Loss 0.5994 | Time(s) 0.4224 | Accuracy 0.6567\n",
      "Epoch 00007 | Loss 0.5969 | Time(s) 0.4254 | Accuracy 0.6567\n",
      "Epoch 00008 | Loss 0.5944 | Time(s) 0.4269 | Accuracy 0.6567\n",
      "Epoch 00009 | Loss 0.5919 | Time(s) 0.4239 | Accuracy 0.6600\n",
      "==============================\n",
      "Test Accuracy 0.7180\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "g, features, labels, train_mask, val_mask, test_mask = load_cora_data()\n",
    "loss_fcn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = th.optim.Adam(net.parameters(), lr=1e-3)\n",
    "dur = []\n",
    "\n",
    "for epoch in range(10):  # 150 epoch accuracy converge, loss still decrease\n",
    "    if epoch >=3:\n",
    "        t0 = time.time()\n",
    "\n",
    "    logits = net(g, features)\n",
    "    loss = loss_fcn(logits[train_mask], labels[train_mask])\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch >=3:\n",
    "        dur.append(time.time() - t0)\n",
    "        \n",
    "    acc = evaluate(logits, labels, val_mask)\n",
    "    print(\"Epoch {:05d} | Loss {:.4f} | Time(s) {:.4f} | Accuracy {:.4f}\".format(\n",
    "            epoch, loss.item(), np.mean(dur), acc))\n",
    "\n",
    "print('='*30)\n",
    "acc = evaluate(logits, labels, test_mask)\n",
    "print(\"Test Accuracy {:.4f}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Graph Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-d94b9db481b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mGraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_edge_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1005\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Graph' is not defined"
     ]
    }
   ],
   "source": [
    "Graph.get_edge_data(0,1005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000 | Loss 0.6809 | Time(s) nan | Accuracy 0.7067\n",
      "Epoch 00001 | Loss 1.1180 | Time(s) nan | Accuracy 0.7033\n",
      "Epoch 00002 | Loss 1.6188 | Time(s) nan | Accuracy 0.7033\n",
      "Epoch 00003 | Loss 0.9237 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00004 | Loss 0.8939 | Time(s) 0.5716 | Accuracy 0.7033\n",
      "Epoch 00005 | Loss 1.1269 | Time(s) 0.5715 | Accuracy 0.7033\n",
      "Epoch 00006 | Loss 0.9651 | Time(s) 0.5713 | Accuracy 0.7033\n",
      "Epoch 00007 | Loss 0.7476 | Time(s) 0.5713 | Accuracy 0.7067\n",
      "Epoch 00008 | Loss 0.8192 | Time(s) 0.5713 | Accuracy 0.7067\n",
      "Epoch 00009 | Loss 0.9524 | Time(s) 0.5711 | Accuracy 0.7067\n",
      "Epoch 00010 | Loss 0.8622 | Time(s) 0.5710 | Accuracy 0.7067\n",
      "Epoch 00011 | Loss 0.7139 | Time(s) 0.5710 | Accuracy 0.7033\n",
      "Epoch 00012 | Loss 0.7394 | Time(s) 0.5710 | Accuracy 0.7033\n",
      "Epoch 00013 | Loss 0.8486 | Time(s) 0.5709 | Accuracy 0.7033\n",
      "Epoch 00014 | Loss 0.8207 | Time(s) 0.5714 | Accuracy 0.7033\n",
      "Epoch 00015 | Loss 0.7135 | Time(s) 0.5716 | Accuracy 0.7033\n",
      "Epoch 00016 | Loss 0.7036 | Time(s) 0.5716 | Accuracy 0.7033\n",
      "Epoch 00017 | Loss 0.7719 | Time(s) 0.5719 | Accuracy 0.7067\n",
      "Epoch 00018 | Loss 0.7783 | Time(s) 0.5719 | Accuracy 0.7067\n",
      "Epoch 00019 | Loss 0.7166 | Time(s) 0.5720 | Accuracy 0.7033\n",
      "Epoch 00020 | Loss 0.6896 | Time(s) 0.5719 | Accuracy 0.7033\n",
      "Epoch 00021 | Loss 0.7229 | Time(s) 0.5720 | Accuracy 0.7033\n",
      "Epoch 00022 | Loss 0.7466 | Time(s) 0.5718 | Accuracy 0.7033\n",
      "Epoch 00023 | Loss 0.7218 | Time(s) 0.5716 | Accuracy 0.7033\n",
      "Epoch 00024 | Loss 0.6881 | Time(s) 0.5716 | Accuracy 0.7033\n",
      "Epoch 00025 | Loss 0.6933 | Time(s) 0.5714 | Accuracy 0.7033\n",
      "Epoch 00026 | Loss 0.7192 | Time(s) 0.5711 | Accuracy 0.7033\n",
      "Epoch 00027 | Loss 0.7158 | Time(s) 0.5709 | Accuracy 0.7033\n",
      "Epoch 00028 | Loss 0.6882 | Time(s) 0.5708 | Accuracy 0.7033\n",
      "Epoch 00029 | Loss 0.6826 | Time(s) 0.5707 | Accuracy 0.7033\n",
      "Epoch 00030 | Loss 0.7017 | Time(s) 0.5706 | Accuracy 0.7033\n",
      "Epoch 00031 | Loss 0.7061 | Time(s) 0.5707 | Accuracy 0.7033\n",
      "Epoch 00032 | Loss 0.6889 | Time(s) 0.5706 | Accuracy 0.7033\n",
      "Epoch 00033 | Loss 0.6807 | Time(s) 0.5705 | Accuracy 0.7033\n",
      "Epoch 00034 | Loss 0.6904 | Time(s) 0.5704 | Accuracy 0.7033\n",
      "Epoch 00035 | Loss 0.6957 | Time(s) 0.5703 | Accuracy 0.7033\n",
      "Epoch 00036 | Loss 0.6865 | Time(s) 0.5702 | Accuracy 0.7033\n",
      "Epoch 00037 | Loss 0.6790 | Time(s) 0.5702 | Accuracy 0.7033\n",
      "Epoch 00038 | Loss 0.6843 | Time(s) 0.5702 | Accuracy 0.7033\n",
      "Epoch 00039 | Loss 0.6901 | Time(s) 0.5702 | Accuracy 0.7033\n",
      "Epoch 00040 | Loss 0.6844 | Time(s) 0.5701 | Accuracy 0.7033\n",
      "Epoch 00041 | Loss 0.6779 | Time(s) 0.5704 | Accuracy 0.7033\n",
      "Epoch 00042 | Loss 0.6815 | Time(s) 0.5715 | Accuracy 0.7033\n",
      "Epoch 00043 | Loss 0.6854 | Time(s) 0.5717 | Accuracy 0.7033\n",
      "Epoch 00044 | Loss 0.6812 | Time(s) 0.5719 | Accuracy 0.7033\n",
      "Epoch 00045 | Loss 0.6776 | Time(s) 0.5729 | Accuracy 0.7033\n",
      "Epoch 00046 | Loss 0.6802 | Time(s) 0.5738 | Accuracy 0.7033\n",
      "Epoch 00047 | Loss 0.6821 | Time(s) 0.5739 | Accuracy 0.7033\n",
      "Epoch 00048 | Loss 0.6791 | Time(s) 0.5746 | Accuracy 0.7033\n",
      "Epoch 00049 | Loss 0.6770 | Time(s) 0.5755 | Accuracy 0.7033\n",
      "Epoch 00050 | Loss 0.6790 | Time(s) 0.5755 | Accuracy 0.7033\n",
      "Epoch 00051 | Loss 0.6802 | Time(s) 0.5756 | Accuracy 0.7033\n",
      "Epoch 00052 | Loss 0.6776 | Time(s) 0.5756 | Accuracy 0.7033\n",
      "Epoch 00053 | Loss 0.6764 | Time(s) 0.5757 | Accuracy 0.7033\n",
      "Epoch 00054 | Loss 0.6783 | Time(s) 0.5757 | Accuracy 0.7033\n",
      "Epoch 00055 | Loss 0.6783 | Time(s) 0.5758 | Accuracy 0.7033\n",
      "Epoch 00056 | Loss 0.6765 | Time(s) 0.5759 | Accuracy 0.7033\n",
      "Epoch 00057 | Loss 0.6765 | Time(s) 0.5766 | Accuracy 0.7033\n",
      "Epoch 00058 | Loss 0.6774 | Time(s) 0.5766 | Accuracy 0.7033\n",
      "Epoch 00059 | Loss 0.6768 | Time(s) 0.5766 | Accuracy 0.7033\n",
      "Epoch 00060 | Loss 0.6758 | Time(s) 0.5766 | Accuracy 0.7033\n",
      "Epoch 00061 | Loss 0.6762 | Time(s) 0.5766 | Accuracy 0.7033\n",
      "Epoch 00062 | Loss 0.6768 | Time(s) 0.5765 | Accuracy 0.7033\n",
      "Epoch 00063 | Loss 0.6759 | Time(s) 0.5765 | Accuracy 0.7033\n",
      "Epoch 00064 | Loss 0.6754 | Time(s) 0.5771 | Accuracy 0.7033\n",
      "Epoch 00065 | Loss 0.6760 | Time(s) 0.5771 | Accuracy 0.7033\n",
      "Epoch 00066 | Loss 0.6759 | Time(s) 0.5772 | Accuracy 0.7033\n",
      "Epoch 00067 | Loss 0.6752 | Time(s) 0.5772 | Accuracy 0.7033\n",
      "Epoch 00068 | Loss 0.6753 | Time(s) 0.5772 | Accuracy 0.7033\n",
      "Epoch 00069 | Loss 0.6755 | Time(s) 0.5772 | Accuracy 0.7033\n",
      "Epoch 00070 | Loss 0.6752 | Time(s) 0.5771 | Accuracy 0.7033\n",
      "Epoch 00071 | Loss 0.6749 | Time(s) 0.5770 | Accuracy 0.7033\n",
      "Epoch 00072 | Loss 0.6751 | Time(s) 0.5770 | Accuracy 0.7033\n",
      "Epoch 00073 | Loss 0.6750 | Time(s) 0.5770 | Accuracy 0.7033\n",
      "Epoch 00074 | Loss 0.6746 | Time(s) 0.5769 | Accuracy 0.7033\n",
      "Epoch 00075 | Loss 0.6746 | Time(s) 0.5768 | Accuracy 0.7033\n",
      "Epoch 00076 | Loss 0.6747 | Time(s) 0.5768 | Accuracy 0.7033\n",
      "Epoch 00077 | Loss 0.6745 | Time(s) 0.5767 | Accuracy 0.7033\n",
      "Epoch 00078 | Loss 0.6743 | Time(s) 0.5766 | Accuracy 0.7033\n",
      "Epoch 00079 | Loss 0.6744 | Time(s) 0.5766 | Accuracy 0.7033\n",
      "Epoch 00080 | Loss 0.6743 | Time(s) 0.5765 | Accuracy 0.7033\n",
      "Epoch 00081 | Loss 0.6741 | Time(s) 0.5764 | Accuracy 0.7033\n",
      "Epoch 00082 | Loss 0.6741 | Time(s) 0.5764 | Accuracy 0.7033\n",
      "Epoch 00083 | Loss 0.6741 | Time(s) 0.5764 | Accuracy 0.7033\n",
      "Epoch 00084 | Loss 0.6739 | Time(s) 0.5763 | Accuracy 0.7033\n",
      "Epoch 00085 | Loss 0.6738 | Time(s) 0.5762 | Accuracy 0.7033\n",
      "Epoch 00086 | Loss 0.6738 | Time(s) 0.5762 | Accuracy 0.7033\n",
      "Epoch 00087 | Loss 0.6736 | Time(s) 0.5761 | Accuracy 0.7033\n",
      "Epoch 00088 | Loss 0.6735 | Time(s) 0.5760 | Accuracy 0.7033\n",
      "Epoch 00089 | Loss 0.6735 | Time(s) 0.5759 | Accuracy 0.7033\n",
      "Epoch 00090 | Loss 0.6734 | Time(s) 0.5759 | Accuracy 0.7033\n",
      "Epoch 00091 | Loss 0.6733 | Time(s) 0.5758 | Accuracy 0.7033\n",
      "Epoch 00092 | Loss 0.6733 | Time(s) 0.5757 | Accuracy 0.7033\n",
      "Epoch 00093 | Loss 0.6732 | Time(s) 0.5757 | Accuracy 0.7033\n",
      "Epoch 00094 | Loss 0.6731 | Time(s) 0.5756 | Accuracy 0.7033\n",
      "Epoch 00095 | Loss 0.6730 | Time(s) 0.5756 | Accuracy 0.7033\n",
      "Epoch 00096 | Loss 0.6730 | Time(s) 0.5755 | Accuracy 0.7033\n",
      "Epoch 00097 | Loss 0.6728 | Time(s) 0.5754 | Accuracy 0.7033\n",
      "Epoch 00098 | Loss 0.6728 | Time(s) 0.5754 | Accuracy 0.7033\n",
      "Epoch 00099 | Loss 0.6727 | Time(s) 0.5753 | Accuracy 0.7033\n",
      "Epoch 00100 | Loss 0.6726 | Time(s) 0.5753 | Accuracy 0.7033\n",
      "Epoch 00101 | Loss 0.6725 | Time(s) 0.5752 | Accuracy 0.7033\n",
      "Epoch 00102 | Loss 0.6725 | Time(s) 0.5752 | Accuracy 0.7033\n",
      "Epoch 00103 | Loss 0.6724 | Time(s) 0.5751 | Accuracy 0.7033\n",
      "Epoch 00104 | Loss 0.6723 | Time(s) 0.5751 | Accuracy 0.7033\n",
      "Epoch 00105 | Loss 0.6722 | Time(s) 0.5750 | Accuracy 0.7033\n",
      "Epoch 00106 | Loss 0.6721 | Time(s) 0.5750 | Accuracy 0.7033\n",
      "Epoch 00107 | Loss 0.6721 | Time(s) 0.5749 | Accuracy 0.7033\n",
      "Epoch 00108 | Loss 0.6720 | Time(s) 0.5749 | Accuracy 0.7033\n",
      "Epoch 00109 | Loss 0.6719 | Time(s) 0.5748 | Accuracy 0.7033\n",
      "Epoch 00110 | Loss 0.6718 | Time(s) 0.5748 | Accuracy 0.7033\n",
      "Epoch 00111 | Loss 0.6717 | Time(s) 0.5747 | Accuracy 0.7033\n",
      "Epoch 00112 | Loss 0.6717 | Time(s) 0.5747 | Accuracy 0.7033\n",
      "Epoch 00113 | Loss 0.6716 | Time(s) 0.5746 | Accuracy 0.7033\n",
      "Epoch 00114 | Loss 0.6715 | Time(s) 0.5745 | Accuracy 0.7033\n",
      "Epoch 00115 | Loss 0.6714 | Time(s) 0.5744 | Accuracy 0.7033\n",
      "Epoch 00116 | Loss 0.6713 | Time(s) 0.5743 | Accuracy 0.7033\n",
      "Epoch 00117 | Loss 0.6713 | Time(s) 0.5742 | Accuracy 0.7033\n",
      "Epoch 00118 | Loss 0.6712 | Time(s) 0.5741 | Accuracy 0.7033\n",
      "Epoch 00119 | Loss 0.6711 | Time(s) 0.5740 | Accuracy 0.7033\n",
      "Epoch 00120 | Loss 0.6710 | Time(s) 0.5739 | Accuracy 0.7033\n",
      "Epoch 00121 | Loss 0.6709 | Time(s) 0.5739 | Accuracy 0.7033\n",
      "Epoch 00122 | Loss 0.6709 | Time(s) 0.5738 | Accuracy 0.7033\n",
      "Epoch 00123 | Loss 0.6708 | Time(s) 0.5737 | Accuracy 0.7033\n",
      "Epoch 00124 | Loss 0.6707 | Time(s) 0.5736 | Accuracy 0.7033\n",
      "Epoch 00125 | Loss 0.6706 | Time(s) 0.5735 | Accuracy 0.7033\n",
      "Epoch 00126 | Loss 0.6705 | Time(s) 0.5735 | Accuracy 0.7033\n",
      "Epoch 00127 | Loss 0.6704 | Time(s) 0.5734 | Accuracy 0.7033\n",
      "Epoch 00128 | Loss 0.6704 | Time(s) 0.5734 | Accuracy 0.7033\n",
      "Epoch 00129 | Loss 0.6703 | Time(s) 0.5733 | Accuracy 0.7033\n",
      "Epoch 00130 | Loss 0.6702 | Time(s) 0.5732 | Accuracy 0.7033\n",
      "Epoch 00131 | Loss 0.6701 | Time(s) 0.5731 | Accuracy 0.7033\n",
      "Epoch 00132 | Loss 0.6700 | Time(s) 0.5731 | Accuracy 0.7033\n",
      "Epoch 00133 | Loss 0.6699 | Time(s) 0.5730 | Accuracy 0.7033\n",
      "Epoch 00134 | Loss 0.6699 | Time(s) 0.5730 | Accuracy 0.7033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00135 | Loss 0.6698 | Time(s) 0.5729 | Accuracy 0.7033\n",
      "Epoch 00136 | Loss 0.6697 | Time(s) 0.5728 | Accuracy 0.7033\n",
      "Epoch 00137 | Loss 0.6696 | Time(s) 0.5728 | Accuracy 0.7033\n",
      "Epoch 00138 | Loss 0.6695 | Time(s) 0.5727 | Accuracy 0.7033\n",
      "Epoch 00139 | Loss 0.6694 | Time(s) 0.5727 | Accuracy 0.7033\n",
      "Epoch 00140 | Loss 0.6694 | Time(s) 0.5726 | Accuracy 0.7033\n",
      "Epoch 00141 | Loss 0.6693 | Time(s) 0.5726 | Accuracy 0.7033\n",
      "Epoch 00142 | Loss 0.6692 | Time(s) 0.5725 | Accuracy 0.7033\n",
      "Epoch 00143 | Loss 0.6691 | Time(s) 0.5725 | Accuracy 0.7033\n",
      "Epoch 00144 | Loss 0.6690 | Time(s) 0.5724 | Accuracy 0.7033\n",
      "Epoch 00145 | Loss 0.6689 | Time(s) 0.5724 | Accuracy 0.7033\n",
      "Epoch 00146 | Loss 0.6688 | Time(s) 0.5723 | Accuracy 0.7033\n",
      "Epoch 00147 | Loss 0.6688 | Time(s) 0.5722 | Accuracy 0.7033\n",
      "Epoch 00148 | Loss 0.6687 | Time(s) 0.5722 | Accuracy 0.7033\n",
      "Epoch 00149 | Loss 0.6686 | Time(s) 0.5721 | Accuracy 0.7033\n",
      "Epoch 00150 | Loss 0.6685 | Time(s) 0.5721 | Accuracy 0.7033\n",
      "Epoch 00151 | Loss 0.6684 | Time(s) 0.5721 | Accuracy 0.7033\n",
      "Epoch 00152 | Loss 0.6683 | Time(s) 0.5720 | Accuracy 0.7033\n",
      "Epoch 00153 | Loss 0.6682 | Time(s) 0.5721 | Accuracy 0.7033\n",
      "Epoch 00154 | Loss 0.6682 | Time(s) 0.5721 | Accuracy 0.7033\n",
      "Epoch 00155 | Loss 0.6681 | Time(s) 0.5721 | Accuracy 0.7033\n",
      "Epoch 00156 | Loss 0.6680 | Time(s) 0.5722 | Accuracy 0.7033\n",
      "Epoch 00157 | Loss 0.6679 | Time(s) 0.5721 | Accuracy 0.7033\n",
      "Epoch 00158 | Loss 0.6678 | Time(s) 0.5721 | Accuracy 0.7033\n",
      "Epoch 00159 | Loss 0.6677 | Time(s) 0.5721 | Accuracy 0.7033\n",
      "Epoch 00160 | Loss 0.6676 | Time(s) 0.5721 | Accuracy 0.7033\n",
      "Epoch 00161 | Loss 0.6675 | Time(s) 0.5720 | Accuracy 0.7033\n",
      "Epoch 00162 | Loss 0.6675 | Time(s) 0.5720 | Accuracy 0.7033\n",
      "Epoch 00163 | Loss 0.6674 | Time(s) 0.5721 | Accuracy 0.7033\n",
      "Epoch 00164 | Loss 0.6673 | Time(s) 0.5721 | Accuracy 0.7033\n",
      "Epoch 00165 | Loss 0.6672 | Time(s) 0.5720 | Accuracy 0.7033\n",
      "Epoch 00166 | Loss 0.6671 | Time(s) 0.5720 | Accuracy 0.7033\n",
      "Epoch 00167 | Loss 0.6670 | Time(s) 0.5720 | Accuracy 0.7033\n",
      "Epoch 00168 | Loss 0.6669 | Time(s) 0.5720 | Accuracy 0.7033\n",
      "Epoch 00169 | Loss 0.6668 | Time(s) 0.5719 | Accuracy 0.7033\n",
      "Epoch 00170 | Loss 0.6667 | Time(s) 0.5719 | Accuracy 0.7033\n",
      "Epoch 00171 | Loss 0.6667 | Time(s) 0.5719 | Accuracy 0.7033\n",
      "Epoch 00172 | Loss 0.6666 | Time(s) 0.5719 | Accuracy 0.7033\n",
      "Epoch 00173 | Loss 0.6665 | Time(s) 0.5719 | Accuracy 0.7033\n",
      "Epoch 00174 | Loss 0.6664 | Time(s) 0.5719 | Accuracy 0.7033\n",
      "Epoch 00175 | Loss 0.6663 | Time(s) 0.5719 | Accuracy 0.7033\n",
      "Epoch 00176 | Loss 0.6662 | Time(s) 0.5719 | Accuracy 0.7033\n",
      "Epoch 00177 | Loss 0.6661 | Time(s) 0.5719 | Accuracy 0.7033\n",
      "Epoch 00178 | Loss 0.6660 | Time(s) 0.5719 | Accuracy 0.7033\n",
      "Epoch 00179 | Loss 0.6659 | Time(s) 0.5719 | Accuracy 0.7033\n",
      "Epoch 00180 | Loss 0.6659 | Time(s) 0.5719 | Accuracy 0.7033\n",
      "Epoch 00181 | Loss 0.6658 | Time(s) 0.5718 | Accuracy 0.7033\n",
      "Epoch 00182 | Loss 0.6657 | Time(s) 0.5718 | Accuracy 0.7033\n",
      "Epoch 00183 | Loss 0.6656 | Time(s) 0.5718 | Accuracy 0.7033\n",
      "Epoch 00184 | Loss 0.6655 | Time(s) 0.5719 | Accuracy 0.7033\n",
      "Epoch 00185 | Loss 0.6654 | Time(s) 0.5718 | Accuracy 0.7033\n",
      "Epoch 00186 | Loss 0.6653 | Time(s) 0.5718 | Accuracy 0.7033\n",
      "Epoch 00187 | Loss 0.6652 | Time(s) 0.5718 | Accuracy 0.7033\n",
      "Epoch 00188 | Loss 0.6651 | Time(s) 0.5718 | Accuracy 0.7033\n",
      "Epoch 00189 | Loss 0.6650 | Time(s) 0.5718 | Accuracy 0.7033\n",
      "Epoch 00190 | Loss 0.6649 | Time(s) 0.5718 | Accuracy 0.7033\n",
      "Epoch 00191 | Loss 0.6648 | Time(s) 0.5717 | Accuracy 0.7033\n",
      "Epoch 00192 | Loss 0.6648 | Time(s) 0.5717 | Accuracy 0.7033\n",
      "Epoch 00193 | Loss 0.6647 | Time(s) 0.5717 | Accuracy 0.7033\n",
      "Epoch 00194 | Loss 0.6646 | Time(s) 0.5717 | Accuracy 0.7033\n",
      "Epoch 00195 | Loss 0.6645 | Time(s) 0.5717 | Accuracy 0.7033\n",
      "Epoch 00196 | Loss 0.6644 | Time(s) 0.5716 | Accuracy 0.7033\n",
      "Epoch 00197 | Loss 0.6643 | Time(s) 0.5716 | Accuracy 0.7067\n",
      "Epoch 00198 | Loss 0.6642 | Time(s) 0.5716 | Accuracy 0.7067\n",
      "Epoch 00199 | Loss 0.6641 | Time(s) 0.5716 | Accuracy 0.7067\n",
      "Epoch 00200 | Loss 0.6640 | Time(s) 0.5716 | Accuracy 0.7067\n",
      "Epoch 00201 | Loss 0.6639 | Time(s) 0.5716 | Accuracy 0.7067\n",
      "Epoch 00202 | Loss 0.6638 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00203 | Loss 0.6637 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00204 | Loss 0.6636 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00205 | Loss 0.6635 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00206 | Loss 0.6635 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00207 | Loss 0.6634 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00208 | Loss 0.6633 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00209 | Loss 0.6632 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00210 | Loss 0.6631 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00211 | Loss 0.6630 | Time(s) 0.5716 | Accuracy 0.7067\n",
      "Epoch 00212 | Loss 0.6629 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00213 | Loss 0.6628 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00214 | Loss 0.6627 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00215 | Loss 0.6626 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00216 | Loss 0.6625 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00217 | Loss 0.6624 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00218 | Loss 0.6623 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00219 | Loss 0.6622 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00220 | Loss 0.6621 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00221 | Loss 0.6620 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00222 | Loss 0.6619 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00223 | Loss 0.6618 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00224 | Loss 0.6618 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00225 | Loss 0.6617 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00226 | Loss 0.6616 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00227 | Loss 0.6615 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00228 | Loss 0.6614 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00229 | Loss 0.6613 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00230 | Loss 0.6612 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00231 | Loss 0.6611 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00232 | Loss 0.6610 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00233 | Loss 0.6609 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00234 | Loss 0.6608 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00235 | Loss 0.6607 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00236 | Loss 0.6606 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00237 | Loss 0.6605 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00238 | Loss 0.6604 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00239 | Loss 0.6603 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00240 | Loss 0.6602 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00241 | Loss 0.6601 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00242 | Loss 0.6600 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00243 | Loss 0.6599 | Time(s) 0.5714 | Accuracy 0.7067\n",
      "Epoch 00244 | Loss 0.6598 | Time(s) 0.5714 | Accuracy 0.7067\n",
      "Epoch 00245 | Loss 0.6597 | Time(s) 0.5714 | Accuracy 0.7067\n",
      "Epoch 00246 | Loss 0.6596 | Time(s) 0.5714 | Accuracy 0.7067\n",
      "Epoch 00247 | Loss 0.6595 | Time(s) 0.5714 | Accuracy 0.7067\n",
      "Epoch 00248 | Loss 0.6594 | Time(s) 0.5713 | Accuracy 0.7067\n",
      "Epoch 00249 | Loss 0.6593 | Time(s) 0.5714 | Accuracy 0.7067\n",
      "Epoch 00250 | Loss 0.6592 | Time(s) 0.5715 | Accuracy 0.7067\n",
      "Epoch 00251 | Loss 0.6591 | Time(s) 0.5717 | Accuracy 0.7067\n",
      "Epoch 00252 | Loss 0.6590 | Time(s) 0.5719 | Accuracy 0.7067\n",
      "Epoch 00253 | Loss 0.6589 | Time(s) 0.5720 | Accuracy 0.7067\n",
      "Epoch 00254 | Loss 0.6588 | Time(s) 0.5722 | Accuracy 0.7067\n",
      "Epoch 00255 | Loss 0.6587 | Time(s) 0.5724 | Accuracy 0.7033\n",
      "Epoch 00256 | Loss 0.6586 | Time(s) 0.5725 | Accuracy 0.7033\n",
      "Epoch 00257 | Loss 0.6585 | Time(s) 0.5727 | Accuracy 0.7033\n",
      "Epoch 00258 | Loss 0.6584 | Time(s) 0.5727 | Accuracy 0.7033\n",
      "Epoch 00259 | Loss 0.6583 | Time(s) 0.5729 | Accuracy 0.7033\n",
      "Epoch 00260 | Loss 0.6582 | Time(s) 0.5729 | Accuracy 0.7033\n",
      "Epoch 00261 | Loss 0.6581 | Time(s) 0.5729 | Accuracy 0.7033\n",
      "Epoch 00262 | Loss 0.6580 | Time(s) 0.5731 | Accuracy 0.7033\n",
      "Epoch 00263 | Loss 0.6579 | Time(s) 0.5733 | Accuracy 0.7033\n",
      "Epoch 00264 | Loss 0.6578 | Time(s) 0.5733 | Accuracy 0.7033\n",
      "Epoch 00265 | Loss 0.6577 | Time(s) 0.5733 | Accuracy 0.7033\n",
      "Epoch 00266 | Loss 0.6576 | Time(s) 0.5733 | Accuracy 0.7033\n",
      "Epoch 00267 | Loss 0.6575 | Time(s) 0.5735 | Accuracy 0.7033\n",
      "Epoch 00268 | Loss 0.6574 | Time(s) 0.5736 | Accuracy 0.7033\n",
      "Epoch 00269 | Loss 0.6573 | Time(s) 0.5738 | Accuracy 0.7033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00270 | Loss 0.6572 | Time(s) 0.5739 | Accuracy 0.7033\n",
      "Epoch 00271 | Loss 0.6571 | Time(s) 0.5739 | Accuracy 0.7033\n",
      "Epoch 00272 | Loss 0.6570 | Time(s) 0.5739 | Accuracy 0.7033\n",
      "Epoch 00273 | Loss 0.6569 | Time(s) 0.5741 | Accuracy 0.7033\n",
      "Epoch 00274 | Loss 0.6568 | Time(s) 0.5743 | Accuracy 0.7033\n",
      "Epoch 00275 | Loss 0.6567 | Time(s) 0.5745 | Accuracy 0.7033\n",
      "Epoch 00276 | Loss 0.6566 | Time(s) 0.5746 | Accuracy 0.7033\n",
      "Epoch 00277 | Loss 0.6565 | Time(s) 0.5748 | Accuracy 0.7033\n",
      "Epoch 00278 | Loss 0.6564 | Time(s) 0.5749 | Accuracy 0.7033\n",
      "Epoch 00279 | Loss 0.6563 | Time(s) 0.5750 | Accuracy 0.7033\n",
      "Epoch 00280 | Loss 0.6563 | Time(s) 0.5750 | Accuracy 0.7033\n",
      "Epoch 00281 | Loss 0.6562 | Time(s) 0.5750 | Accuracy 0.7033\n",
      "Epoch 00282 | Loss 0.6561 | Time(s) 0.5750 | Accuracy 0.7033\n",
      "Epoch 00283 | Loss 0.6560 | Time(s) 0.5751 | Accuracy 0.7033\n",
      "Epoch 00284 | Loss 0.6559 | Time(s) 0.5750 | Accuracy 0.7033\n",
      "Epoch 00285 | Loss 0.6557 | Time(s) 0.5750 | Accuracy 0.7033\n",
      "Epoch 00286 | Loss 0.6556 | Time(s) 0.5750 | Accuracy 0.7033\n",
      "Epoch 00287 | Loss 0.6555 | Time(s) 0.5749 | Accuracy 0.7033\n",
      "Epoch 00288 | Loss 0.6554 | Time(s) 0.5749 | Accuracy 0.7033\n",
      "Epoch 00289 | Loss 0.6553 | Time(s) 0.5749 | Accuracy 0.7033\n",
      "Epoch 00290 | Loss 0.6552 | Time(s) 0.5748 | Accuracy 0.7033\n",
      "Epoch 00291 | Loss 0.6551 | Time(s) 0.5748 | Accuracy 0.7033\n",
      "Epoch 00292 | Loss 0.6550 | Time(s) 0.5748 | Accuracy 0.7033\n",
      "Epoch 00293 | Loss 0.6549 | Time(s) 0.5748 | Accuracy 0.7033\n",
      "Epoch 00294 | Loss 0.6548 | Time(s) 0.5747 | Accuracy 0.7033\n",
      "Epoch 00295 | Loss 0.6547 | Time(s) 0.5747 | Accuracy 0.7033\n",
      "Epoch 00296 | Loss 0.6546 | Time(s) 0.5747 | Accuracy 0.7033\n",
      "Epoch 00297 | Loss 0.6545 | Time(s) 0.5746 | Accuracy 0.7033\n",
      "Epoch 00298 | Loss 0.6544 | Time(s) 0.5746 | Accuracy 0.7033\n",
      "Epoch 00299 | Loss 0.6543 | Time(s) 0.5746 | Accuracy 0.7033\n",
      "Epoch 00300 | Loss 0.6542 | Time(s) 0.5746 | Accuracy 0.7033\n",
      "Epoch 00301 | Loss 0.6541 | Time(s) 0.5745 | Accuracy 0.7033\n",
      "Epoch 00302 | Loss 0.6540 | Time(s) 0.5745 | Accuracy 0.7033\n",
      "Epoch 00303 | Loss 0.6539 | Time(s) 0.5745 | Accuracy 0.7033\n",
      "Epoch 00304 | Loss 0.6538 | Time(s) 0.5745 | Accuracy 0.7033\n",
      "Epoch 00305 | Loss 0.6537 | Time(s) 0.5744 | Accuracy 0.7033\n",
      "Epoch 00306 | Loss 0.6536 | Time(s) 0.5744 | Accuracy 0.7033\n",
      "Epoch 00307 | Loss 0.6535 | Time(s) 0.5744 | Accuracy 0.7033\n",
      "Epoch 00308 | Loss 0.6534 | Time(s) 0.5743 | Accuracy 0.7033\n",
      "Epoch 00309 | Loss 0.6533 | Time(s) 0.5743 | Accuracy 0.7033\n",
      "Epoch 00310 | Loss 0.6532 | Time(s) 0.5743 | Accuracy 0.7033\n",
      "Epoch 00311 | Loss 0.6531 | Time(s) 0.5743 | Accuracy 0.7033\n",
      "Epoch 00312 | Loss 0.6530 | Time(s) 0.5742 | Accuracy 0.7033\n",
      "Epoch 00313 | Loss 0.6529 | Time(s) 0.5742 | Accuracy 0.7033\n",
      "Epoch 00314 | Loss 0.6528 | Time(s) 0.5742 | Accuracy 0.7033\n",
      "Epoch 00315 | Loss 0.6527 | Time(s) 0.5742 | Accuracy 0.7033\n",
      "Epoch 00316 | Loss 0.6526 | Time(s) 0.5741 | Accuracy 0.7033\n",
      "Epoch 00317 | Loss 0.6525 | Time(s) 0.5741 | Accuracy 0.7033\n",
      "Epoch 00318 | Loss 0.6524 | Time(s) 0.5741 | Accuracy 0.7033\n",
      "Epoch 00319 | Loss 0.6523 | Time(s) 0.5741 | Accuracy 0.7033\n",
      "Epoch 00320 | Loss 0.6522 | Time(s) 0.5740 | Accuracy 0.7033\n",
      "Epoch 00321 | Loss 0.6521 | Time(s) 0.5740 | Accuracy 0.7033\n",
      "Epoch 00322 | Loss 0.6520 | Time(s) 0.5740 | Accuracy 0.7033\n",
      "Epoch 00323 | Loss 0.6519 | Time(s) 0.5739 | Accuracy 0.7033\n",
      "Epoch 00324 | Loss 0.6518 | Time(s) 0.5739 | Accuracy 0.7033\n",
      "Epoch 00325 | Loss 0.6517 | Time(s) 0.5739 | Accuracy 0.7033\n",
      "Epoch 00326 | Loss 0.6515 | Time(s) 0.5739 | Accuracy 0.7033\n",
      "Epoch 00327 | Loss 0.6514 | Time(s) 0.5738 | Accuracy 0.7033\n",
      "Epoch 00328 | Loss 0.6513 | Time(s) 0.5738 | Accuracy 0.7033\n",
      "Epoch 00329 | Loss 0.6512 | Time(s) 0.5738 | Accuracy 0.7033\n",
      "Epoch 00330 | Loss 0.6511 | Time(s) 0.5738 | Accuracy 0.7033\n",
      "Epoch 00331 | Loss 0.6510 | Time(s) 0.5738 | Accuracy 0.7033\n",
      "Epoch 00332 | Loss 0.6509 | Time(s) 0.5738 | Accuracy 0.7033\n",
      "Epoch 00333 | Loss 0.6508 | Time(s) 0.5737 | Accuracy 0.7033\n",
      "Epoch 00334 | Loss 0.6507 | Time(s) 0.5737 | Accuracy 0.7033\n",
      "Epoch 00335 | Loss 0.6506 | Time(s) 0.5737 | Accuracy 0.7033\n",
      "Epoch 00336 | Loss 0.6505 | Time(s) 0.5737 | Accuracy 0.7033\n",
      "Epoch 00337 | Loss 0.6504 | Time(s) 0.5737 | Accuracy 0.7033\n",
      "Epoch 00338 | Loss 0.6503 | Time(s) 0.5737 | Accuracy 0.7033\n",
      "Epoch 00339 | Loss 0.6502 | Time(s) 0.5737 | Accuracy 0.7033\n",
      "Epoch 00340 | Loss 0.6501 | Time(s) 0.5737 | Accuracy 0.7033\n",
      "Epoch 00341 | Loss 0.6500 | Time(s) 0.5737 | Accuracy 0.7033\n",
      "Epoch 00342 | Loss 0.6499 | Time(s) 0.5737 | Accuracy 0.7033\n",
      "Epoch 00343 | Loss 0.6498 | Time(s) 0.5736 | Accuracy 0.7033\n",
      "Epoch 00344 | Loss 0.6497 | Time(s) 0.5736 | Accuracy 0.7033\n",
      "Epoch 00345 | Loss 0.6495 | Time(s) 0.5736 | Accuracy 0.7033\n",
      "Epoch 00346 | Loss 0.6494 | Time(s) 0.5736 | Accuracy 0.7033\n",
      "Epoch 00347 | Loss 0.6493 | Time(s) 0.5736 | Accuracy 0.7033\n",
      "Epoch 00348 | Loss 0.6492 | Time(s) 0.5735 | Accuracy 0.7033\n",
      "Epoch 00349 | Loss 0.6491 | Time(s) 0.5735 | Accuracy 0.7033\n",
      "Epoch 00350 | Loss 0.6490 | Time(s) 0.5735 | Accuracy 0.7033\n",
      "Epoch 00351 | Loss 0.6489 | Time(s) 0.5735 | Accuracy 0.7033\n",
      "Epoch 00352 | Loss 0.6488 | Time(s) 0.5735 | Accuracy 0.7033\n",
      "Epoch 00353 | Loss 0.6487 | Time(s) 0.5735 | Accuracy 0.7033\n",
      "Epoch 00354 | Loss 0.6486 | Time(s) 0.5734 | Accuracy 0.7033\n",
      "Epoch 00355 | Loss 0.6485 | Time(s) 0.5734 | Accuracy 0.7033\n",
      "Epoch 00356 | Loss 0.6484 | Time(s) 0.5734 | Accuracy 0.7033\n",
      "Epoch 00357 | Loss 0.6483 | Time(s) 0.5734 | Accuracy 0.7033\n",
      "Epoch 00358 | Loss 0.6482 | Time(s) 0.5734 | Accuracy 0.7033\n",
      "Epoch 00359 | Loss 0.6481 | Time(s) 0.5734 | Accuracy 0.7033\n",
      "Epoch 00360 | Loss 0.6480 | Time(s) 0.5733 | Accuracy 0.7033\n",
      "Epoch 00361 | Loss 0.6479 | Time(s) 0.5733 | Accuracy 0.7033\n",
      "Epoch 00362 | Loss 0.6478 | Time(s) 0.5733 | Accuracy 0.7033\n",
      "Epoch 00363 | Loss 0.6477 | Time(s) 0.5733 | Accuracy 0.7033\n",
      "Epoch 00364 | Loss 0.6476 | Time(s) 0.5732 | Accuracy 0.7033\n",
      "Epoch 00365 | Loss 0.6475 | Time(s) 0.5732 | Accuracy 0.7033\n",
      "Epoch 00366 | Loss 0.6474 | Time(s) 0.5732 | Accuracy 0.7033\n",
      "Epoch 00367 | Loss 0.6473 | Time(s) 0.5732 | Accuracy 0.7033\n",
      "Epoch 00368 | Loss 0.6473 | Time(s) 0.5731 | Accuracy 0.7033\n",
      "Epoch 00369 | Loss 0.6473 | Time(s) 0.5731 | Accuracy 0.7033\n",
      "Epoch 00370 | Loss 0.6473 | Time(s) 0.5731 | Accuracy 0.7033\n",
      "Epoch 00371 | Loss 0.6474 | Time(s) 0.5731 | Accuracy 0.7033\n",
      "Epoch 00372 | Loss 0.6475 | Time(s) 0.5730 | Accuracy 0.7033\n",
      "Epoch 00373 | Loss 0.6476 | Time(s) 0.5730 | Accuracy 0.7033\n",
      "Epoch 00374 | Loss 0.6476 | Time(s) 0.5730 | Accuracy 0.7033\n",
      "Epoch 00375 | Loss 0.6475 | Time(s) 0.5730 | Accuracy 0.7033\n",
      "Epoch 00376 | Loss 0.6473 | Time(s) 0.5729 | Accuracy 0.7033\n",
      "Epoch 00377 | Loss 0.6470 | Time(s) 0.5729 | Accuracy 0.7033\n",
      "Epoch 00378 | Loss 0.6467 | Time(s) 0.5729 | Accuracy 0.7033\n",
      "Epoch 00379 | Loss 0.6464 | Time(s) 0.5729 | Accuracy 0.7033\n",
      "Epoch 00380 | Loss 0.6461 | Time(s) 0.5728 | Accuracy 0.7033\n",
      "Epoch 00381 | Loss 0.6458 | Time(s) 0.5728 | Accuracy 0.7033\n",
      "Epoch 00382 | Loss 0.6457 | Time(s) 0.5728 | Accuracy 0.7033\n",
      "Epoch 00383 | Loss 0.6455 | Time(s) 0.5728 | Accuracy 0.7033\n",
      "Epoch 00384 | Loss 0.6455 | Time(s) 0.5728 | Accuracy 0.7033\n",
      "Epoch 00385 | Loss 0.6454 | Time(s) 0.5727 | Accuracy 0.7033\n",
      "Epoch 00386 | Loss 0.6454 | Time(s) 0.5727 | Accuracy 0.7033\n",
      "Epoch 00387 | Loss 0.6454 | Time(s) 0.5727 | Accuracy 0.7033\n",
      "Epoch 00388 | Loss 0.6455 | Time(s) 0.5727 | Accuracy 0.7033\n",
      "Epoch 00389 | Loss 0.6456 | Time(s) 0.5727 | Accuracy 0.7033\n",
      "Epoch 00390 | Loss 0.6457 | Time(s) 0.5727 | Accuracy 0.7033\n",
      "Epoch 00391 | Loss 0.6460 | Time(s) 0.5727 | Accuracy 0.7033\n",
      "Epoch 00392 | Loss 0.6464 | Time(s) 0.5727 | Accuracy 0.7033\n",
      "Epoch 00393 | Loss 0.6470 | Time(s) 0.5727 | Accuracy 0.7033\n",
      "Epoch 00394 | Loss 0.6479 | Time(s) 0.5727 | Accuracy 0.7033\n",
      "Epoch 00395 | Loss 0.6501 | Time(s) 0.5728 | Accuracy 0.7033\n",
      "Epoch 00396 | Loss 0.6533 | Time(s) 0.5728 | Accuracy 0.7033\n",
      "Epoch 00397 | Loss 0.6576 | Time(s) 0.5728 | Accuracy 0.7033\n",
      "Epoch 00398 | Loss 0.6617 | Time(s) 0.5728 | Accuracy 0.7033\n",
      "Epoch 00399 | Loss 0.6633 | Time(s) 0.5728 | Accuracy 0.7033\n",
      "==============================\n",
      "Test Accuracy 0.5640\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "g, features, labels, train_mask, val_mask, test_mask = load_cora_data()\n",
    "loss_fcn = th.nn.CrossEntropyLoss()\n",
    "optimizer = th.optim.Adam(net.parameters(), lr=1e-3)\n",
    "dur = []\n",
    "\n",
    "for epoch in range(400):  #  epoch converge\n",
    "    if epoch >=3:\n",
    "        t0 = time.time()\n",
    "\n",
    "    logits = net(g, features)\n",
    "    loss = loss_fcn(logits[train_mask], labels[train_mask])\n",
    "    for nodei, nodej in zip(g.edges()[0], g.edges()[1]):\n",
    "        if train_mask[nodei] == 0 or train_mask[nodej] == 0:\n",
    "            continue\n",
    "        else:\n",
    "            loss += sum((logits[nodei] - logits[nodej]) ** 2)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch >=3:\n",
    "        dur.append(time.time() - t0)\n",
    "        \n",
    "    acc = evaluate(logits, labels, val_mask)\n",
    "    print(\"Epoch {:05d} | Loss {:.4f} | Time(s) {:.4f} | Accuracy {:.4f}\".format(\n",
    "            epoch, loss.item(), np.mean(dur), acc))\n",
    "\n",
    "print('='*30)\n",
    "acc = evaluate(logits, labels, test_mask)\n",
    "print(\"Test Accuracy {:.4f}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((np.arange(9) - np.arange(5,14))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
